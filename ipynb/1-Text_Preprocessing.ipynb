{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMjudf8aCNeHR7PKN1Jhptb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Text Preprocessing"],"metadata":{"id":"eiUQhuYdPgVD"}},{"cell_type":"markdown","source":["## Introduction\n","\n","Text pre-processing is a crucial step in the Natural Language Processing (NLP) pipeline. Before any sophisticated algorithms can be applied to text data, it must first be cleaned and transformed into a format that is suitable for analysis. Raw text data is often noisy and unstructured, containing inconsistencies, irrelevant information, and various linguistic peculiarities. Effective pre-processing improves the quality of the data, making it more accessible and interpretable for NLP models. By reducing noise and standardizing the text, we can enhance the performance of machine learning models and ensure more accurate and reliable results.\n","\n","We will explore the primary techniques used in text pre-processing. These techniques help in preparing raw text data for further analysis and modeling. The key techniques we will cover include:\n","\n","- Tokenization: breaking down text into individual tokens.\n","- Removing Stop Words: eliminating common words that do not contribute much to the meaning (e.g., \"and\", \"the\", \"is\").\n","- Lemmatization and Stemming: reducing words to their base or root form.\n","\n","NLTK (Natural Language Toolkit) will be our main library (https://www.nltk.org/).\n","\n","By the end of this notebook, you will have a comprehensive understanding of these pre-processing techniques and be able to apply them to your own text data, preparing it for successful NLP applications."],"metadata":{"id":"wRssrCA6Pdw6"}},{"cell_type":"markdown","source":["The following code snippet downloads the necessary models for NLTK. You need to run this code before performing any tasks to ensure that NLTK has the required data files."],"metadata":{"id":"AY_c7xJdRIwa"}},{"cell_type":"code","source":["from nltk import download\n","download('punkt')\n","download('stopwords')\n","download('wordnet')\n","download('averaged_perceptron_tagger')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DYKUXr-vQGS_","executionInfo":{"status":"ok","timestamp":1719045238805,"user_tz":-120,"elapsed":2402,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"353094ea-c512-452d-db0a-bb06f8a28a80"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["## Tokenization"],"metadata":{"id":"EEbpH-d6QIqw"}},{"cell_type":"markdown","source":["Let's import the functions `sent_tokenize` and `word_tokenize` from the `nltk` module. These two functions allow us to split text into sentences and words, respectively.\n"],"metadata":{"id":"9BQ39xdnRK3h"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"wLZK3qx3Ok9Z","executionInfo":{"status":"ok","timestamp":1719045238805,"user_tz":-120,"elapsed":14,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}}},"outputs":[],"source":["from nltk import sent_tokenize, word_tokenize"]},{"cell_type":"markdown","source":["We take some lines from the introduction to \"1984\" by George Orwell as an example of text."],"metadata":{"id":"T8z2UN4ZR0Fc"}},{"cell_type":"code","source":["sample_text = \"\"\"It was a bright cold day in April, and the clocks were striking thirteen.\n","Winston Smith, his chin nuzzled into his breast in an effort to escape the\n","vile wind, slipped quickly through the glass doors of Victory Mansions,\n","though not quickly enough to prevent a swirl of gritty dust from entering\n","along with him.\n","\n","The hallway smelt of boiled cabbage and old rag mats. At one end of it a\n","coloured poster, too large for indoor display, had been tacked to the wall.\n","It depicted simply an enormous face, more than a metre wide: the face of a\n","man of about forty-five, with a heavy black moustache and ruggedly handsome\n","features. Winston made for the stairs. It was no use trying the lift. Even\n","at the best of times it was seldom working, and at present the electric\n","current was cut off during daylight hours. It was part of the economy drive\n","in preparation for Hate Week. The flat was seven flights up, and Winston,\n","who was thirty-nine and had a varicose ulcer above his right ankle, went\n","slowly, resting several times on the way. On each landing, opposite the\n","lift-shaft, the poster with the enormous face gazed from the wall. It was\n","one of those pictures which are so contrived that the eyes follow you about\n","when you move. BIG BROTHER IS WATCHING YOU, the caption beneath it ran.\"\"\""],"metadata":{"id":"uY28CUIbRzRp","executionInfo":{"status":"ok","timestamp":1719045238805,"user_tz":-120,"elapsed":13,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["The result of the tokenization into sentences is a list where each element is a sentence."],"metadata":{"id":"T9PqrbPlSZlq"}},{"cell_type":"code","source":["sentence_tokens = sent_tokenize(sample_text)\n","print(\"Result type: \", type(sentence_tokens))\n","print(\"Result: \", sentence_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N2kYNkfiShHR","executionInfo":{"status":"ok","timestamp":1719045238805,"user_tz":-120,"elapsed":13,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"fe7e7f48-600d-4dbb-d5d8-383ea301392c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Result type:  <class 'list'>\n","Result:  ['It was a bright cold day in April, and the clocks were striking thirteen.', 'Winston Smith, his chin nuzzled into his breast in an effort to escape the\\nvile wind, slipped quickly through the glass doors of Victory Mansions,\\nthough not quickly enough to prevent a swirl of gritty dust from entering\\nalong with him.', 'The hallway smelt of boiled cabbage and old rag mats.', 'At one end of it a\\ncoloured poster, too large for indoor display, had been tacked to the wall.', 'It depicted simply an enormous face, more than a metre wide: the face of a\\nman of about forty-five, with a heavy black moustache and ruggedly handsome\\nfeatures.', 'Winston made for the stairs.', 'It was no use trying the lift.', 'Even\\nat the best of times it was seldom working, and at present the electric\\ncurrent was cut off during daylight hours.', 'It was part of the economy drive\\nin preparation for Hate Week.', 'The flat was seven flights up, and Winston,\\nwho was thirty-nine and had a varicose ulcer above his right ankle, went\\nslowly, resting several times on the way.', 'On each landing, opposite the\\nlift-shaft, the poster with the enormous face gazed from the wall.', 'It was\\none of those pictures which are so contrived that the eyes follow you about\\nwhen you move.', 'BIG BROTHER IS WATCHING YOU, the caption beneath it ran.']\n"]}]},{"cell_type":"markdown","source":["The result of the tokenization into words is a list where each element is a word or a punctuation mark."],"metadata":{"id":"n6IB2ZewTgEN"}},{"cell_type":"code","source":["word_tokens = word_tokenize(sample_text)\n","print(\"Result type: \", type(word_tokens))\n","print(\"Result: \", word_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AOokqz9fS287","executionInfo":{"status":"ok","timestamp":1719045238805,"user_tz":-120,"elapsed":10,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"6c3d06f0-7f44-48fe-d84f-b1fe05ec29e8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Result type:  <class 'list'>\n","Result:  ['It', 'was', 'a', 'bright', 'cold', 'day', 'in', 'April', ',', 'and', 'the', 'clocks', 'were', 'striking', 'thirteen', '.', 'Winston', 'Smith', ',', 'his', 'chin', 'nuzzled', 'into', 'his', 'breast', 'in', 'an', 'effort', 'to', 'escape', 'the', 'vile', 'wind', ',', 'slipped', 'quickly', 'through', 'the', 'glass', 'doors', 'of', 'Victory', 'Mansions', ',', 'though', 'not', 'quickly', 'enough', 'to', 'prevent', 'a', 'swirl', 'of', 'gritty', 'dust', 'from', 'entering', 'along', 'with', 'him', '.', 'The', 'hallway', 'smelt', 'of', 'boiled', 'cabbage', 'and', 'old', 'rag', 'mats', '.', 'At', 'one', 'end', 'of', 'it', 'a', 'coloured', 'poster', ',', 'too', 'large', 'for', 'indoor', 'display', ',', 'had', 'been', 'tacked', 'to', 'the', 'wall', '.', 'It', 'depicted', 'simply', 'an', 'enormous', 'face', ',', 'more', 'than', 'a', 'metre', 'wide', ':', 'the', 'face', 'of', 'a', 'man', 'of', 'about', 'forty-five', ',', 'with', 'a', 'heavy', 'black', 'moustache', 'and', 'ruggedly', 'handsome', 'features', '.', 'Winston', 'made', 'for', 'the', 'stairs', '.', 'It', 'was', 'no', 'use', 'trying', 'the', 'lift', '.', 'Even', 'at', 'the', 'best', 'of', 'times', 'it', 'was', 'seldom', 'working', ',', 'and', 'at', 'present', 'the', 'electric', 'current', 'was', 'cut', 'off', 'during', 'daylight', 'hours', '.', 'It', 'was', 'part', 'of', 'the', 'economy', 'drive', 'in', 'preparation', 'for', 'Hate', 'Week', '.', 'The', 'flat', 'was', 'seven', 'flights', 'up', ',', 'and', 'Winston', ',', 'who', 'was', 'thirty-nine', 'and', 'had', 'a', 'varicose', 'ulcer', 'above', 'his', 'right', 'ankle', ',', 'went', 'slowly', ',', 'resting', 'several', 'times', 'on', 'the', 'way', '.', 'On', 'each', 'landing', ',', 'opposite', 'the', 'lift-shaft', ',', 'the', 'poster', 'with', 'the', 'enormous', 'face', 'gazed', 'from', 'the', 'wall', '.', 'It', 'was', 'one', 'of', 'those', 'pictures', 'which', 'are', 'so', 'contrived', 'that', 'the', 'eyes', 'follow', 'you', 'about', 'when', 'you', 'move', '.', 'BIG', 'BROTHER', 'IS', 'WATCHING', 'YOU', ',', 'the', 'caption', 'beneath', 'it', 'ran', '.']\n"]}]},{"cell_type":"markdown","source":["**Bonus**: What's the average number of words per sentence?"],"metadata":{"id":"uXwtELVCUC48"}},{"cell_type":"markdown","source":["To answer the question, we have to remove all the punctuation marks from the `word_tokens` list. For this purpose, we can use the `string` package: it contains the `punctuation` constant, which is a string of all punctuation characters. By leveraging this constant, we can filter out the punctuation marks from our list of word tokens."],"metadata":{"id":"UMaxeCLiUrjB"}},{"cell_type":"code","source":["from string import punctuation\n","print(\"Punctuation constant: \", punctuation)\n","\n","word_tokens_no_punctuation = [word for word in word_tokens if word not in punctuation]\n","print(\"Result: \", word_tokens_no_punctuation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8-Nuq_zHTt97","executionInfo":{"status":"ok","timestamp":1719045238805,"user_tz":-120,"elapsed":8,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"ce80e7ca-47ac-48b7-d395-3c5f59994b86"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Punctuation constant:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","Result:  ['It', 'was', 'a', 'bright', 'cold', 'day', 'in', 'April', 'and', 'the', 'clocks', 'were', 'striking', 'thirteen', 'Winston', 'Smith', 'his', 'chin', 'nuzzled', 'into', 'his', 'breast', 'in', 'an', 'effort', 'to', 'escape', 'the', 'vile', 'wind', 'slipped', 'quickly', 'through', 'the', 'glass', 'doors', 'of', 'Victory', 'Mansions', 'though', 'not', 'quickly', 'enough', 'to', 'prevent', 'a', 'swirl', 'of', 'gritty', 'dust', 'from', 'entering', 'along', 'with', 'him', 'The', 'hallway', 'smelt', 'of', 'boiled', 'cabbage', 'and', 'old', 'rag', 'mats', 'At', 'one', 'end', 'of', 'it', 'a', 'coloured', 'poster', 'too', 'large', 'for', 'indoor', 'display', 'had', 'been', 'tacked', 'to', 'the', 'wall', 'It', 'depicted', 'simply', 'an', 'enormous', 'face', 'more', 'than', 'a', 'metre', 'wide', 'the', 'face', 'of', 'a', 'man', 'of', 'about', 'forty-five', 'with', 'a', 'heavy', 'black', 'moustache', 'and', 'ruggedly', 'handsome', 'features', 'Winston', 'made', 'for', 'the', 'stairs', 'It', 'was', 'no', 'use', 'trying', 'the', 'lift', 'Even', 'at', 'the', 'best', 'of', 'times', 'it', 'was', 'seldom', 'working', 'and', 'at', 'present', 'the', 'electric', 'current', 'was', 'cut', 'off', 'during', 'daylight', 'hours', 'It', 'was', 'part', 'of', 'the', 'economy', 'drive', 'in', 'preparation', 'for', 'Hate', 'Week', 'The', 'flat', 'was', 'seven', 'flights', 'up', 'and', 'Winston', 'who', 'was', 'thirty-nine', 'and', 'had', 'a', 'varicose', 'ulcer', 'above', 'his', 'right', 'ankle', 'went', 'slowly', 'resting', 'several', 'times', 'on', 'the', 'way', 'On', 'each', 'landing', 'opposite', 'the', 'lift-shaft', 'the', 'poster', 'with', 'the', 'enormous', 'face', 'gazed', 'from', 'the', 'wall', 'It', 'was', 'one', 'of', 'those', 'pictures', 'which', 'are', 'so', 'contrived', 'that', 'the', 'eyes', 'follow', 'you', 'about', 'when', 'you', 'move', 'BIG', 'BROTHER', 'IS', 'WATCHING', 'YOU', 'the', 'caption', 'beneath', 'it', 'ran']\n"]}]},{"cell_type":"markdown","source":["Now, we can calculate the average number of words per sentence by dividing the length of the `word_tokens_no_punctuation` list by the length of the `sentence_tokens` list."],"metadata":{"id":"aZQCVZmIWEnr"}},{"cell_type":"code","source":["sentence_tokens_length = len(sentence_tokens)\n","word_tokens_no_punctuation_length = len(word_tokens_no_punctuation)\n","average_words_per_sentence = word_tokens_no_punctuation_length/sentence_tokens_length\n","print(\"Avg. word per sentence: \", average_words_per_sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0hKpuMwxVEGQ","executionInfo":{"status":"ok","timestamp":1719045238806,"user_tz":-120,"elapsed":7,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"f34e39ca-e468-4ee2-90da-c9036014219c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Avg. word per sentence:  17.76923076923077\n"]}]},{"cell_type":"markdown","source":["There are, on average, 18 words per sentence in the first lines of \"1984\" by George Orwell!"],"metadata":{"id":"cX5ieplhW4Id"}},{"cell_type":"markdown","source":["## Removing Stopwords"],"metadata":{"id":"QjLg9ikay_KF"}},{"cell_type":"markdown","source":["We can remove stopwords by tokenizing the text at the word level and removing from the resulting list all words that are contained in a predefined list of stopwords available in the `nltk` module. So, let's import the already seen `word_tokenize` function and the list of stopwords."],"metadata":{"id":"z0ZL-gtqzUqn"}},{"cell_type":"code","source":["from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords"],"metadata":{"id":"ZSLpIvJlzBTm","executionInfo":{"status":"ok","timestamp":1719045238806,"user_tz":-120,"elapsed":6,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["We can see the first ten predefined stopwords for the English language as an example."],"metadata":{"id":"2-8RTs4G0XN5"}},{"cell_type":"code","source":["stopwords_list = stopwords.words('english')\n","print(\"First ten stopwords: \", stopwords_list[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E-Em-CSR0Zzc","executionInfo":{"status":"ok","timestamp":1719045238806,"user_tz":-120,"elapsed":6,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"1144d136-1215-4162-c82c-7adf2684ca49"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["First ten stopwords:  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"]}]},{"cell_type":"markdown","source":["We take some lines from the introduction to \"1984\" by George Orwell as an example of text."],"metadata":{"id":"NZLvrH6v1WeT"}},{"cell_type":"code","source":["sample_text = \"\"\"It was a bright cold day in April, and the clocks were striking thirteen.\n","Winston Smith, his chin nuzzled into his breast in an effort to escape the\n","vile wind, slipped quickly through the glass doors of Victory Mansions,\n","though not quickly enough to prevent a swirl of gritty dust from entering\n","along with him.\n","\n","The hallway smelt of boiled cabbage and old rag mats. At one end of it a\n","coloured poster, too large for indoor display, had been tacked to the wall.\n","It depicted simply an enormous face, more than a metre wide: the face of a\n","man of about forty-five, with a heavy black moustache and ruggedly handsome\n","features. Winston made for the stairs. It was no use trying the lift. Even\n","at the best of times it was seldom working, and at present the electric\n","current was cut off during daylight hours. It was part of the economy drive\n","in preparation for Hate Week. The flat was seven flights up, and Winston,\n","who was thirty-nine and had a varicose ulcer above his right ankle, went\n","slowly, resting several times on the way. On each landing, opposite the\n","lift-shaft, the poster with the enormous face gazed from the wall. It was\n","one of those pictures which are so contrived that the eyes follow you about\n","when you move. BIG BROTHER IS WATCHING YOU, the caption beneath it ran.\"\"\""],"metadata":{"id":"Vh46Rb5s1WeU","executionInfo":{"status":"ok","timestamp":1719045238806,"user_tz":-120,"elapsed":5,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Now we remove the stopwords from the text. To check if a word is contained in the stopwords list, we should lowercase that word, because the `stopwords_list` contains only lowercased words."],"metadata":{"id":"VnLe5pTa1YkJ"}},{"cell_type":"code","source":["word_tokens = word_tokenize(sample_text)\n","word_tokens_no_stopwords = [word for word in word_tokens if word.lower() not in stopwords_list]\n","sample_text_no_stopwords = ' '.join(word_tokens_no_stopwords)\n","print(\"Result: \", sample_text_no_stopwords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BaUTQM580cig","executionInfo":{"status":"ok","timestamp":1719045238806,"user_tz":-120,"elapsed":5,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"fb3556d5-301f-4b55-fb95-a24a2595653a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Result:  bright cold day April , clocks striking thirteen . Winston Smith , chin nuzzled breast effort escape vile wind , slipped quickly glass doors Victory Mansions , though quickly enough prevent swirl gritty dust entering along . hallway smelt boiled cabbage old rag mats . one end coloured poster , large indoor display , tacked wall . depicted simply enormous face , metre wide : face man forty-five , heavy black moustache ruggedly handsome features . Winston made stairs . use trying lift . Even best times seldom working , present electric current cut daylight hours . part economy drive preparation Hate Week . flat seven flights , Winston , thirty-nine varicose ulcer right ankle , went slowly , resting several times way . landing , opposite lift-shaft , poster enormous face gazed wall . one pictures contrived eyes follow move . BIG BROTHER WATCHING , caption beneath ran .\n"]}]},{"cell_type":"markdown","source":["## Lemmatization and Stemming"],"metadata":{"id":"Vg6RN6tn32v-"}},{"cell_type":"markdown","source":["Stemming and lemmatization are techniques used to normalize text, but they have different advantages and disadvantages. Stemming is faster and more straightforward, as it simply chops off word endings to reach the root form, but it can result in non-dictionary words and less accurate base forms. Lemmatization, on the other hand, is more accurate as it reduces words to their dictionary forms using morphological analysis, but it is slower and requires more computational resources. While stemming is suitable for applications where speed is crucial and exact base forms are less important, lemmatization is preferred in contexts where grammatical correctness and precision are essential.\n","\n","Let's start with stemming and import the `PorterStemmer` object from `nltk`."],"metadata":{"id":"D64SujjR4UZu"}},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","stemmer = PorterStemmer()"],"metadata":{"id":"bhCs0EmH1uqH","executionInfo":{"status":"ok","timestamp":1719045238806,"user_tz":-120,"elapsed":4,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["For this demonstration, we will start by using a simple list of four words."],"metadata":{"id":"4EhSQS3_4hZf"}},{"cell_type":"code","source":["sample_words = [\"run\", \"running\", \"runner\", \"ran\", \"runs\"]\n","print(\"Sample list of words: \", sample_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G3M7O2GK4ga-","executionInfo":{"status":"ok","timestamp":1719045239161,"user_tz":-120,"elapsed":359,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"5e715c95-1ab1-4d89-e00d-3a3b194a6ed7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Sample list of words:  ['run', 'running', 'runner', 'ran', 'runs']\n"]}]},{"cell_type":"markdown","source":["We will now see how stemming modifies that list."],"metadata":{"id":"Q-RZ30K15HxL"}},{"cell_type":"code","source":["stemmed_words = [stemmer.stem(word) for word in sample_words]\n","print(\"Result: \", stemmed_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DSNFxNI95HLc","executionInfo":{"status":"ok","timestamp":1719045239161,"user_tz":-120,"elapsed":2,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"7d6dc013-9621-4a10-8cc8-b59911a30f36"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Result:  ['run', 'run', 'runner', 'ran', 'run']\n"]}]},{"cell_type":"markdown","source":["Stemming has reduced the different verb forms to the same root. We note that stemming typically does not handle irregular verbs well because it applies a simple rule-based approach to strip suffixes, leading to less accurate results. For example, the word 'ran' is stemmed to 'ran' instead of the correct base form 'run'. What about lemmatization? Let's try using the `WordNetLemmatizer` object from the `nltk` library. With the parameter `pos='v'`, we treat each word as a verb during the lemmatization."],"metadata":{"id":"9LdY09-l5xDA"}},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","\n","lemmatizer = WordNetLemmatizer()\n","sample_words = [\"run\", \"running\", \"runner\", \"ran\", \"runs\"]\n","lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in sample_words]  # 'v' indica che trattiamo i verbi\n","\n","print(\"Result: \", lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N992M015P5U","executionInfo":{"status":"ok","timestamp":1719045242834,"user_tz":-120,"elapsed":3674,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"4502b395-4e37-4b76-c970-01939d96e7b0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Result:  ['run', 'run', 'runner', 'run', 'run']\n"]}]},{"cell_type":"markdown","source":["Using lemmatization, the different forms of the verb 'run' have been converted to their base form 'run', except for 'runner', which is already a noun. What if we treat each word as a noun?"],"metadata":{"id":"_OAEf9f669Rs"}},{"cell_type":"code","source":["lemmatizer = WordNetLemmatizer()\n","sample_words = [\"run\", \"running\", \"runner\", \"ran\", \"runs\"]\n","lemmatized_words = [lemmatizer.lemmatize(word, pos='n') for word in sample_words]  # 'v' indica che trattiamo i verbi\n","\n","print(\"Result: \", lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DwpehNbB9CTY","executionInfo":{"status":"ok","timestamp":1719045242835,"user_tz":-120,"elapsed":6,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"1511a008-7473-4319-c831-a7f3061e9d41"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Result:  ['run', 'running', 'runner', 'ran', 'run']\n"]}]},{"cell_type":"markdown","source":["When lemmatizing the list ['run', 'running', 'runner', 'ran', 'runs'] with pos='n' (as nouns), the result was ['run', 'running', 'runner', 'ran', 'run']. \"Running\" and \"runner\" remained unchanged as they were treated as nouns, and only \"runs\" was correctly lemmatized to \"run\". This highlights the importance of specifying the correct part of speech for accurate lemmatization."],"metadata":{"id":"acbzISmx9GqM"}},{"cell_type":"markdown","source":["**Bonus**: Now, we will lemmatize the introduction of \"1984\" by George Orwell."],"metadata":{"id":"XZ5r4foS7kx6"}},{"cell_type":"code","source":["sample_text = \"\"\"It was a bright cold day in April, and the clocks were striking thirteen.\n","Winston Smith, his chin nuzzled into his breast in an effort to escape the\n","vile wind, slipped quickly through the glass doors of Victory Mansions,\n","though not quickly enough to prevent a swirl of gritty dust from entering\n","along with him.\n","\n","The hallway smelt of boiled cabbage and old rag mats. At one end of it a\n","coloured poster, too large for indoor display, had been tacked to the wall.\n","It depicted simply an enormous face, more than a metre wide: the face of a\n","man of about forty-five, with a heavy black moustache and ruggedly handsome\n","features. Winston made for the stairs. It was no use trying the lift. Even\n","at the best of times it was seldom working, and at present the electric\n","current was cut off during daylight hours. It was part of the economy drive\n","in preparation for Hate Week. The flat was seven flights up, and Winston,\n","who was thirty-nine and had a varicose ulcer above his right ankle, went\n","slowly, resting several times on the way. On each landing, opposite the\n","lift-shaft, the poster with the enormous face gazed from the wall. It was\n","one of those pictures which are so contrived that the eyes follow you about\n","when you move. BIG BROTHER IS WATCHING YOU, the caption beneath it ran.\"\"\""],"metadata":{"id":"1x78OEnp6SwP","executionInfo":{"status":"ok","timestamp":1719045242835,"user_tz":-120,"elapsed":5,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["To tag each part of speech, we use the basic NLTK model, which is based on a supervised learning algorithm trained on an annotated text corpus."],"metadata":{"id":"F6MeCtwx9tZ6"}},{"cell_type":"code","source":["from nltk import pos_tag\n","\n","word_tokens = word_tokenize(sample_text)\n","tagged_word_tokens = pos_tag(word_tokens)\n","print(\"Result: \", tagged_word_tokens[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4Qx7LIx8PLX","executionInfo":{"status":"ok","timestamp":1719045242835,"user_tz":-120,"elapsed":5,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"8dfc05c2-90fc-4433-8085-6beb29dd00e2"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Result:  [('It', 'PRP'), ('was', 'VBD'), ('a', 'DT'), ('bright', 'JJ'), ('cold', 'JJ'), ('day', 'NN'), ('in', 'IN'), ('April', 'NNP'), (',', ','), ('and', 'CC')]\n"]}]},{"cell_type":"markdown","source":["We define a function that map tags starting with 'J' to adjectives, 'V' to verbs, 'N' to nouns, and 'R' to adverbs. If the tag doesn't match any of these, we assign None to it."],"metadata":{"id":"HjaFa77s-dWj"}},{"cell_type":"code","source":["from nltk.corpus import wordnet\n","\n","def get_wordnet_pos(tag):\n","    if tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif tag.startswith('V'):\n","        return wordnet.VERB\n","    elif tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return None"],"metadata":{"id":"JLm79O1R-RqK","executionInfo":{"status":"ok","timestamp":1719045242835,"user_tz":-120,"elapsed":3,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Now, we can lemmatize the text assigning the correct part of speech tag to each word"],"metadata":{"id":"eJyqE9Gw-rcI"}},{"cell_type":"code","source":["lemmatized_words= []\n","\n","for word, tag in tagged_word_tokens:\n","    wn_tag = get_wordnet_pos(tag)\n","    if wn_tag is not None:\n","        lemmatized_words.append(lemmatizer.lemmatize(word, pos=wn_tag))\n","    else:\n","        lemmatized_words.append(lemmatizer.lemmatize(word))\n","\n","lemmatized_text = ' '.join(lemmatized_words)\n","print(\"Result: \", lemmatized_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTZ0v96J-lI_","executionInfo":{"status":"ok","timestamp":1719045243245,"user_tz":-120,"elapsed":413,"user":{"displayName":"Alex Alborghetti","userId":"02552696889110785741"}},"outputId":"8b5b2d71-519c-4240-dee9-7c6fa7d4fc35"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Result:  It be a bright cold day in April , and the clock be strike thirteen . Winston Smith , his chin nuzzle into his breast in an effort to escape the vile wind , slip quickly through the glass door of Victory Mansions , though not quickly enough to prevent a swirl of gritty dust from enter along with him . The hallway smelt of boiled cabbage and old rag mat . At one end of it a coloured poster , too large for indoor display , have be tack to the wall . It depict simply an enormous face , more than a metre wide : the face of a man of about forty-five , with a heavy black moustache and ruggedly handsome feature . Winston make for the stair . It be no use try the lift . Even at the best of time it be seldom work , and at present the electric current be cut off during daylight hour . It be part of the economy drive in preparation for Hate Week . The flat be seven flight up , and Winston , who be thirty-nine and have a varicose ulcer above his right ankle , go slowly , rest several time on the way . On each landing , opposite the lift-shaft , the poster with the enormous face gaze from the wall . It be one of those picture which be so contrived that the eye follow you about when you move . BIG BROTHER IS WATCHING YOU , the caption beneath it run .\n"]}]},{"cell_type":"markdown","source":["## Conclusion"],"metadata":{"id":"JMgt4G01D0Lb"}},{"cell_type":"markdown","source":["In this notebook, we explored essential text pre-processing techniques for Natural Language Processing (NLP). We covered tokenization, stop word removal, and lemmatization/stemming, demonstrating how to clean and standardize raw text data using NLTK. Proper pre-processing reduces noise and enhances the performance of machine learning models. With these skills, you can effectively prepare your text data for successful NLP applications, ensuring more accurate and reliable results."],"metadata":{"id":"luS_E9R4AHQA"}}]}